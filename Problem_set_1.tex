\documentclass[12pt,onecolumn]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          				PACKAGES  				              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[margin=1.5in]{geometry}
\usepackage{authblk}
%\usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc}
\usepackage{placeins}
\usepackage{amsfonts}
\usepackage{comment}
\usepackage{a4wide,graphicx,color}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage[table]{xcolor}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{dcolumn}
\usepackage{color,soul}
\usepackage{threeparttable}
\usepackage[capposition=top]{floatrow}
\usepackage[labelsep=period]{caption}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{lscape}
\usepackage{pdflscape}
\usepackage{multicol}
\usepackage[bottom]{footmisc}
\setlength\footnotemargin{5pt}
\usepackage{longtable}
\usepackage{chronosys}
\catcode`\@=11
\def\chron@selectmonth#1{\ifcase#1\or Jan\or Feb\or Mar\or Apr\or May\or Jun\or Jul\or Aug\or Sep\or Oct\or Nov\or Dec\fi}

%% BibTeX settings
\usepackage{natbib}
\bibliographystyle{apalike}
\bibpunct{(}{)}{,}{a}{,}{,}

%% markup commands for code/software
\let\code=\texttt
\let\pkg=\textbf
\let\proglang=\textsf
\newcommand{\file}[1]{`\code{#1}'}
\newcommand{\email}[1]{\href{mailto:#1}{\normalfont\texttt{#1}}}
\urlstyle{same}

%% paragraph formatting
\renewcommand{\baselinestretch}{1}

%% \usepackage{Sweave} is essentially
\RequirePackage[T1]{fontenc}
\RequirePackage{ae,fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}

% Defines columns for tables
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


\usepackage{bbm}
\usepackage{enumitem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     			TITLE, AUTHORS AND DATE    			  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Problem Set 1}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Econ 4676: Big Data and Machine Learning for Applied Economics}
\author{{\bf Due Date}: August 24 at 1:00 pm}
\date{The repo link to create your submission is \url{https://classroom.github.com/g/2zlAqMNF}}




\begin{document}
\maketitle

\section{Theory Exercises: Econometrics Review}

\begin{enumerate}

  \item Consider the regression model $y_i = \alpha +\beta x_i +\epsilon, i=1,...,N,$, a model with a constant and a single regressor. Assume that $E(\epsilon_i|x_i)=0$ $\forall i$.
      \begin{enumerate}
        \item Show that $E(\epsilon_i|x_i)=0$ implies  $E(\epsilon_i)=0$ and  $E(\epsilon_i x_i)=0$
        
        \textcolor{blue}{\textbf{Solución}}
        
        Para esta parte, primero probaremos  la ley de esperanzas iteradas (para una variable continua, ya que el caso de una variable discreta es similar). Esta ley nos dice que, dadas dos variables aleatorias  $Z$ y $W$, con función de densidad conjunta $f(Z,W)$, se cumple que 
        
        $$E(Z) = E_{W}(E(Z|W))$$
        
        Para ver el porqué, primero notemos que 
        $$
      E_{W}(E(Z|W))= \int_{-\infty}^{\infty}  E(Z|W) f(W)dW 
       =\int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} Z f(Z|W) dZ\right) f(W)dW 
        $$ 
        donde $f(W)= \int_{-\infty}^{\infty} f(Z,W) dZ$ y $ f(Z|W)= \frac{f(Z,W)}{f(W)} $. Por lo tanto, lo anterior puede escribirse así
        $$
      \int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} Z f(Z|W) f(W) dZ\right) dW = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} Z f(Z,W)  dZ dW 
        $$ y, a su vez, tenemos que esta última expresión puede escribirse así
        $$
        \int_{-\infty}^{\infty}Z \int_{-\infty}^{\infty}  f(Z,W)  dZ dW = \int_{-\infty}^{\infty}Z f(Z) dZ= E(Z)
        $$
        Ahora bien, por la ley de esperanzas iteradas tenemos que 
        
        $$
        E(\epsilon_i)= E_{x_i}(E(\epsilon_i|x_i))= E_{x_i}(0)= 0
        $$
        Por último, para probar el segundo resultado (que $E(\epsilon_i x_i)=0$) también podemos usar la ley de esperanzas iteradas: 
        $$
        E(\epsilon_i x_i)= E_{x_i}( E(\epsilon_i x_i|x_i))= E_{x_i}( x_i E(\epsilon_i |x_i))= E_{x_i}( x_i0)= 0
        $$ 
        \item Use the two previous implications to derive the Method of Moments estimator
        
        \textcolor{blue}{\textbf{Solución}}

        Del anterior punto tenemos los siguientes momentos poblacionales: $E(\epsilon_i)=0$ y   $E(\epsilon_i x_i)=0$. Los estimadores de $\alpha$ y $\beta$, $\hat{\alpha}$ y $\hat{\beta}$, respectivamente, estarán dados por los análogos muestrales de los momentos poblacionales
        
        $$
        \sum_{i=1}^{n} (y_{i}- \hat{\alpha}-\hat{\beta}x_i)=0
        $$
          $$
        \sum_{i=1}^{n} (y_{i}- \hat{\alpha}-\hat{\beta}x_i)x_i=0
        $$
        
        \item Can you accommodate the terms in the previous point to put the estimator in the famous formula $\hat \beta= (X'X)^{-1}X'y$?
      \end{enumerate}
  \item Prove the following properties of $R^2$:
        \begin{enumerate}
              \item The OLS estimator maximizes $R^2$
              \item $0 \leq R^2 \leq 1$
              \item For the two-variable model $Y_i = \alpha + \beta x_i + u_i$, show $r^2 = R^2$, where $r$ is the sample correlation coefficient between $Y$ and $X$.
    \end{enumerate}
    
    
  \item Consider the linear regression $y = \beta_1 \iota + X_2 \beta_2 +u$ where $\iota$ is an n-vector of 1s, and $X_2$ is an $n \times (k-1)$ matrix of observations on the remaining variables. Show, using the FWL Theorem, that the OLS estimators of $\beta_1$ and $\beta_2$ can be written as
  \begin{align}
  \left(\begin{array}{c}
    \hat{\beta_{1}}\\
    \hat{\beta_{2}}
    \end{array}\right)=\left(\begin{array}{cc}
    n & \iota'X_{2}\\
    0 & X_{2}'M_{\iota}X_{2}
    \end{array}\right)^{-1}\left(\begin{array}{c}
    \iota' y\\
    X_{2}'M_{\iota}y
    \end{array}\right)
  \end{align}
  where $M_{\iota}$ is the matrix that takes deviation from the sample mean

  \item Given the model $Y = X \beta + \epsilon$ where $X$ is $n \times k$. Let also $\hat \beta$ denote the OLS estimator and $R^2_k$ denote the  $R^2$ (centered), where the subscript $k$ means a model with $k$ explanatory variables.
  \begin{enumerate}
    \item Show that 
    \begin{align}
      R^2_K = \sum_{k=1}^K \hat \beta_k \frac{\sum_{i=1}^n (X_{ik}-\bar{X}_k)Y_i}{\sum_{i=1}^n (Y_i-\bar Y)^2}
    \end{align}
    where $\hat \beta_k$ is the $k-th$ element of $\hat \beta$, $X_{ik}$ is the $i-th$ element of the $k-th$ explanatory variable, $Y_i$ is the $i-th$ element of Y, $\bar X_k = \sum_{i=1}^n X_{ik}/n$, and $\bar Y = \sum_i^n Y_i/n$
    \item Suppose that you delete an explanatory variable from the model (so that the model has $K-1$ explanatory variables) and obtain $R^2_{K-1}$, show that $R^2_{K}>R^2_{K-1}$
  \end{enumerate}


  \item  Suppose you want to minimize the following function 
  \begin{align}
  f(\beta_1,\beta_2)=\frac{1}{2}(\beta_1^2-\beta_2)^2+ \frac{1}{2}(\beta_1-1)^2
  \end{align}
  \begin{enumerate}
    \item Compute the gradients $\frac{\partial f}{\partial \beta_1}$ and $\frac{\partial f}{\partial \beta_2}$
    \item Write the following function
    \begin{enumerate}
      \item Give initial values $\beta_1$ and $\beta_2$
      \item Until $f(\beta^i_1,\beta^i_2)$ {\it ``does not change much do''}
      \begin{itemize}
       \item $\beta_1^{i+1} = \beta_1^{i} - \eta \frac{\partial f}{\partial \beta_1}$
       \item $\beta_2^{i+1} = \beta_2^{i} - \eta \frac{\partial f}{\partial \beta_2}$
       \item compute $|f^{i+1}-f^{i}|$
       \item if $|f^{i+1}-f^{i}|<tol$ stop, otherwise continue
       \item $i \leftarrow i+1$
      \end{itemize}
      \item here you need to define the step size $\eta$ and what {\it ``does not change much do''}. 
      \begin{enumerate}
        \item Pick a ``small'' step and a ``big'' step. 
        \item Set a high tolerance rate $(tol)$ and a small tolerance rate to define {\it ``does not change much do''}. 
      \end{enumerate}
      \item Graphically illustrate these results
    \end{enumerate}
  \end{enumerate}
        



  

\end{enumerate}



\section{Empirical Problems}

The main objective of these sections is to apply the concepts we learned using ``real" world data. With these, I also expect that you sharpen your data collection and wrangling skills. Finally, you should pay attention to your writing.

I encourage you to turn each of the following two parts of the problem set in a way that resembles a paper. As such, I expect graphs, tables, and writing to be as neat as possible. You can write it in Spanish or English, either language is fine. For students in the Ph.D., it would be a good practice to do it in English.

These parts also involve a lot of coding. Don't forget to upload everything to your repository and follow the template. 

\subsection{Exploring the Housing Market in Colombia}

This part of the problem set involves data on housing prices in Colombia. The data was provided by \url{https://www.properati.com.co}. It contains information on listing prices as well as features of the properties on sale. The data set is called \texttt{co\_properties.csv} and you can download it from \href{https://www.dropbox.com/s/7za955mzf7b7qti/co_properties.zip?dl=0}{here}. 


In this problem set, we will focus only on houses and apartments on sale in Bogotá D.C., Cali, and Medellín. I care only about these types of operations, properties, and cities. You are welcome to use all the data, but results should be relevant for these subgroups.

\begin{enumerate}
  
  \item The data set include multiple variables that can help explain the price of a property.  Choose the most relevant and perform a descriptive analysis of these variables. At a minimum, you should include a descriptive statistics table. Note that there are many observations with missing data. I leave it to you to find a way to handle these missing data. Don't forget to discuss your decisions and the data. Take this section as an opportunity to present a compelling narrative to justify or defend your data choices. Do not present it as a ``dry'' list of ingredients.
  \item Estimate a linear model using OLS of the form
  \begin{equation}
    Y = X\beta +u
  \end{equation}

  Where $Y$ is the asking price and X  is a matrix with the variables you chose to explain the price. I leave it to you to decide which variables to include. Discuss your decisions and results, including a discussion of the fit.
  \item Compute the leverage statistic for each observation. Are there any outliers, i.e., observations with high leverage driving the results?
  \item One difficulty with linear models is that the interpretation of the estimated parameters is intimately connected with the units of measurement of the included variables. However,  it is often convenient to present estimates of semi-elasticities housing prices or even elasticities. Changes in the functional form alter the interpretation and the sample fit. In this part of the problem set, you should explore different functional forms and their fit. You can try one by one, or you can estimate Box-Cox forms or anything you deem sensible.
  \item Once you've chosen your ``preferred functional'' form for the equation, you can also transform your independent variables by adding polynomials and interactions. At this point, explore different transformations of your independent variables. There are two purposes here (1) explore heterogeneity in the sample (2) improve the in-sample fit. You should keep this in mind when discussing your results. One of those models should include the linear and the square term of {\it number of rooms}, compute the number of rooms that maximizes the expected price. Don't forget to calculate also the standard errors. You should discuss the relevance of this result, taking into account the number of rooms observed in the sample.
  \item Estimate your preferred model using the \texttt{QR} decomposition. Compare these results to the traditional \texttt{out of the box} estimation methods results (for example, in \texttt{R} would be comparing it to \texttt{lm}, \texttt{Stata} would be to \texttt{reg}.)
  \item Estimate the preferred model for each of the three cities separately, 
  \begin{enumerate}
    \item Compare it to the model that consolidates the three cities. Show this in a 4 column table. Discuss
    \item Is there a way to recover the linear parameter for  {\it number of rooms} of the consolidated sample by combining the parameters obtained in the separated samples for each city? 
    \item Can you come up with a single equation model that shows the coefficients for {\it number of rooms} for each city? Comment on the size of the coefficients and the standard errors. Are these coefficients the same that you obtained in \texttt{(a)}?
  \end{enumerate}
  

\item How well does your preferred model at predicting asking prices in Barranquilla? Comment in terms of prediction error. If it performs well, argue why, and if not, explain.

\item Are there some other variables missing, e.g., amenities, that could potentially help? How could you obtain these variables and add them to this data set? Here I expect a thoughtful discussion, but if you want to add data, I'll reward you with a bonus on your grade. 

  
\end{enumerate}

\end{document}
